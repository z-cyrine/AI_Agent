# Configuration API pour Llama 3.3 70B

## Provider: Groq

**Avantages:**
- âš¡ **Ultra-rapide** (~280 tokens/sec)
- ðŸ†“ **Quota gratuit gÃ©nÃ©reux** (30 req/min, 6000 tokens/min)
- ðŸŽ¯ **Parfait pour dÃ©veloppement et production**

**Configuration:**

1. CrÃ©er un compte sur [console.groq.com](https://console.groq.com)
2. GÃ©nÃ©rer une clÃ© API dans "API Keys"
3. Dans `.env`:
   ```env
   LLM_PROVIDER=groq
   LLM_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxx
   LLM_MODEL=llama-3.3-70b-versatile
   ```

**ModÃ¨les disponibles:**
- `llama-3.3-70b-versatile` (recommandÃ©)
- `llama-3.1-70b-versatile`

---

## Installation

```bash
# 1. Installer langchain-openai
pip install langchain-openai

# 2. Remplir votre .env avec la clÃ© API
# Voir .env.example pour un template

# 3. Tester
python test_quick.py
```

## VÃ©rification de la Configuration

```bash
# Test rapide de connexion
python -c "from agents.agent1_interpreter import IntentInterpreterAgent; agent = IntentInterpreterAgent(); print('âœ… Configuration OK')"
```

## DÃ©pannage

**Erreur: "API key not found"**
- VÃ©rifiez que `.env` contient bien `LLM_API_KEY=votre_clÃ©`
- VÃ©rifiez qu'il n'y a pas d'espace avant/aprÃ¨s la clÃ©

**Erreur: "Rate limit exceeded"**
- Attendez 1 minute (limite: 30 req/min)
- RÃ©duisez la frÃ©quence des requÃªtes

**Erreur: "Model not found"**
- Utilisez `llama-3.3-70b-versatile` (nom exact)

## ðŸŽ¯ Pourquoi Groq uniquement?

**Pour ce projet IBN:**
- âœ… Gratuit (30 req/min)
- âœ… Ultra-rapide
- âœ… Stable et fiable
- âœ… Largement suffisant pour dÃ©veloppement ET production

**Note**: Le quota de 30 req/min est parfait pour un systÃ¨me IBN!
